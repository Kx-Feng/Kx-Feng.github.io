<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hello! on Xiaoyan Feng</title><link>http://localhost:1313/</link><description>Recent content in Hello! on Xiaoyan Feng</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml"/><item><title>Home</title><link>http://localhost:1313/docs/about_me/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/about_me/</guid><description>About Me#</description></item><item><title>LLM + copyright</title><link>http://localhost:1313/docs/arxiv_papers/llm_copyright/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/arxiv_papers/llm_copyright/</guid><description>Arxiv Papers: LLM meets Copyright#2024-03-15
Lost in Overlap: Exploring Watermark Collision in LLMs
Yiyang Luo, Ke Lin, Chao Gu
abstractabstract: The proliferation of large language models (LLMs) in generating contentraises concerns about text copyright. Watermarking methods, particularlylogit-based approaches, embed imperceptible identifiers into text to addressthese challenges. However, the widespread use of watermarking across diverseLLMs has led to an inevitable issue known as watermark collision during commontasks like question answering and paraphrasing.</description></item><item><title>machine unlearning</title><link>http://localhost:1313/docs/arxiv_papers/machine_unlearning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/arxiv_papers/machine_unlearning/</guid><description>content</description></item><item><title>Vulnerable LLM</title><link>http://localhost:1313/docs/arxiv_papers/vulnerable_llm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/arxiv_papers/vulnerable_llm/</guid><description>content</description></item></channel></rss>